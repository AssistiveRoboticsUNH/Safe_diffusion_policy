{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carl_ma/miniconda3/envs/robodiff/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# use line-buffering for both stdout and stderr\n",
    "# sys.stdout = open(sys.stdout.fileno(), mode='w', buffering=1)\n",
    "# sys.stderr = open(sys.stderr.fileno(), mode='w', buffering=1)\n",
    "\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "import pathlib\n",
    "from diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    " \n",
    "import os\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import random\n",
    "import wandb\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "# from diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    "from diffusion_policy.policy.robomimic_lowdim_policy import RobomimicLowdimPolicy\n",
    "from diffusion_policy.dataset.base_dataset import BaseLowdimDataset\n",
    "from diffusion_policy.env_runner.base_lowdim_runner import BaseLowdimRunner\n",
    "from diffusion_policy.common.checkpoint_util import TopKCheckpointManager\n",
    "from diffusion_policy.common.json_logger import JsonLogger\n",
    "from diffusion_policy.common.pytorch_util import dict_apply, optimizer_to\n",
    "\n",
    "from diffusion_policy.policy.robomimic_lowdim_policy import RobomimicLowdimPolicy\n",
    "from diffusion_policy.policy.robomimic_image_policy import RobomimicImagePolicy\n",
    "from diffusion_policy.dataset.base_dataset import BaseImageDataset\n",
    "from diffusion_policy.env_runner.base_image_runner import BaseImageRunner\n",
    "\n",
    "# from diffusion_policy.workspace.train_diffusion_unet_hybrid_workspace import TrainDiffusionUnetHybridWorkspace\n",
    "import os\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "import pathlib\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "import random\n",
    "import wandb\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "from diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    "from diffusion_policy.policy.diffusion_unet_hybrid_image_policy import DiffusionUnetHybridImagePolicy\n",
    "from diffusion_policy.dataset.base_dataset import BaseImageDataset\n",
    "from diffusion_policy.env_runner.base_image_runner import BaseImageRunner\n",
    "from diffusion_policy.common.checkpoint_util import TopKCheckpointManager\n",
    "from diffusion_policy.common.json_logger import JsonLogger\n",
    "from diffusion_policy.common.pytorch_util import dict_apply, optimizer_to\n",
    "from diffusion_policy.model.diffusion.ema_model import EMAModel\n",
    "from diffusion_policy.model.common.lr_scheduler import get_scheduler\n",
    "\n",
    "from diffusion_policy.dataset.robomimic_replay_image_dataset import RobomimicReplayImageDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, Sampler \n",
    "\n",
    "import h5py\n",
    "\n",
    "# import mimicgen\n",
    "# import mimicgen.utils.file_utils as MG_FileUtils\n",
    "# import mimicgen.utils.robomimic_utils as RobomimicUtils\n",
    "# from mimicgen.utils.misc_utils import add_red_border_to_frame\n",
    "# from mimicgen.configs import MG_TaskSpec\n",
    "\n",
    "OmegaConf.register_new_resolver(\"eval\", eval, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path='.'\n",
    "# config_name = \"image_franka_drawer_lay5_g53.yaml\" \n",
    "# config_name=\"image_franka_image_224\"\n",
    "\n",
    "config_name = \"safe_image_franka_image_240_320\"  # 58 demos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_target_': 'diffusion_policy.workspace.train_diffusion_unet_hybrid_workspace.TrainDiffusionUnetHybridWorkspace', 'checkpoint': {'save_last_ckpt': True, 'save_last_snapshot': False, 'topk': {'format_str': 'epoch={epoch:04d}-test_mean_score={test_mean_score:.3f}.ckpt', 'k': 5, 'mode': 'max', 'monitor_key': 'test_mean_score'}}, 'dataloader': {'batch_size': 64, 'num_workers': 8, 'persistent_workers': False, 'pin_memory': True, 'shuffle': True}, 'dataset_obs_steps': 2, 'ema': {'_target_': 'diffusion_policy.model.diffusion.ema_model.EMAModel', 'inv_gamma': 1.0, 'max_value': 0.9999, 'min_value': 0.0, 'power': 0.75, 'update_after_step': 0}, 'exp_name': 'default', 'horizon': 16, 'keypoint_visible_rate': 1.0, 'logging': {'group': None, 'id': None, 'mode': 'online', 'name': '2025.02.20-22.31.41_train_diffusion_unet_pick_duck_image', 'project': 'diffusion_policy_debug', 'resume': True, 'tags': ['train_diffusion_unet_hybrid', 'square_image', 'default']}, 'multi_run': {'run_dir': 'data/outputs/2022.12.29/2025.02.20-22.31.41_train_diffusion_unet_pick_duck_image', 'wandb_name_base': '2025.02.20-22.31.41_train_diffusion_unet_pick_duck_image'}, 'n_action_steps': 8, 'n_latency_steps': 0, 'n_obs_steps': 2, 'name': 'train_diffusion_unet_hybrid', 'obs_as_global_cond': True, 'optimizer': {'_target_': 'torch.optim.AdamW', 'betas': [0.95, 0.999], 'eps': 1e-08, 'lr': 0.0001, 'weight_decay': 1e-06}, 'past_action_visible': False, 'policy': {'_target_': 'diffusion_policy.policy.diffusion_unet_hybrid_image_policy.DiffusionUnetHybridImagePolicy', 'cond_predict_scale': True, 'crop_shape': [180, 180], 'diffusion_step_embed_dim': 128, 'down_dims': [512, 1024, 2048], 'eval_fixed_crop': True, 'horizon': 16, 'kernel_size': 5, 'n_action_steps': 8, 'n_groups': 8, 'n_obs_steps': 2, 'noise_scheduler': {'_target_': 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler', 'beta_end': 0.02, 'beta_schedule': 'squaredcos_cap_v2', 'beta_start': 0.0001, 'clip_sample': True, 'num_train_timesteps': 100, 'prediction_type': 'epsilon', 'variance_type': 'fixed_small'}, 'num_inference_steps': 100, 'obs_as_global_cond': True, 'obs_encoder_group_norm': True, 'shape_meta': {'action': {'shape': [10]}, 'obs': {'ee_states': {'shape': [16]}, 'joint_states': {'shape': [7]}, 'eye_in_hand_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'gripper_states': {'shape': [1]}}}}, 'shape_meta': {'action': {'shape': [10]}, 'obs': {'ee_states': {'shape': [16]}, 'joint_states': {'shape': [7]}, 'eye_in_hand_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'gripper_states': {'shape': [1]}}}, 'task': {'abs_action': True, 'dataset': {'_target_': 'diffusion_policy.dataset.robomimic_replay_image_dataset.RobomimicReplayImageDataset', 'abs_action': True, 'dataset_path': '/home/carl_ma/Riad/diffusion_policy/dataset/demo_duck_feb12.hdf5', 'horizon': 16, 'n_obs_steps': 2, 'pad_after': 7, 'pad_before': 1, 'rotation_rep': 'rotation_6d', 'seed': 42, 'shape_meta': {'action': {'shape': [10]}, 'obs': {'ee_states': {'shape': [16]}, 'joint_states': {'shape': [7]}, 'eye_in_hand_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'gripper_states': {'shape': [1]}}}, 'use_cache': True, 'val_ratio': 0.02}, 'dataset_path': '/home/carl_ma/Riad/diffusion_policy/dataset/demo_duck_feb12.hdf5', 'dataset_type': 'mh', 'env_runner': {'_target_': 'diffusion_policy.env_runner.robomimic_image_runner.RobomimicImageRunner', 'abs_action': True, 'crf': 22, 'dataset_path': '/home/carl_ma/Riad/diffusion_policy/dataset/demo_duck_feb12.hdf5', 'fps': 10, 'max_steps': 500, 'n_action_steps': 8, 'n_envs': 28, 'n_obs_steps': 2, 'n_test': 50, 'n_test_vis': 4, 'n_train': 6, 'n_train_vis': 2, 'past_action': False, 'render_obs_key': 'eye_in_hand_rgb', 'shape_meta': {'action': {'shape': [10]}, 'obs': {'ee_states': {'shape': [16]}, 'joint_states': {'shape': [7]}, 'eye_in_hand_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'gripper_states': {'shape': [1]}}}, 'test_start_seed': 100000, 'tqdm_interval_sec': 1.0, 'train_start_idx': 0}, 'name': 'duck_image', 'shape_meta': {'action': {'shape': [10]}, 'obs': {'ee_states': {'shape': [16]}, 'joint_states': {'shape': [7]}, 'eye_in_hand_rgb': {'shape': [3, 240, 320], 'type': 'rgb'}, 'gripper_states': {'shape': [1]}}}, 'task_name': 'pick'}, 'task_name': 'duck_image', 'training': {'checkpoint_every': 50, 'debug': False, 'device': 'cuda:0', 'gradient_accumulate_every': 1, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 500, 'max_train_steps': None, 'max_val_steps': None, 'num_epochs': 1000, 'resume': True, 'rollout_every': 50, 'sample_every': 5, 'seed': 42, 'tqdm_interval_sec': 1.0, 'use_ema': True, 'val_every': 1}, 'val_dataloader': {'batch_size': 64, 'num_workers': 8, 'persistent_workers': False, 'pin_memory': True, 'shuffle': False}}\n",
      "resume:  True\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=config_path):\n",
    "    cfg_org = compose(\n",
    "        config_name=config_name,\n",
    "        overrides=[\n",
    "            \"hydra.run.dir=data/outputs/${now:%Y.%m.%d}/${now:%H.%M.%S}_${name}_${task_name}\",\n",
    "            \"training.seed=42\",\n",
    "            \"training.device=cuda:0\"\n",
    "        ],\n",
    "    )\n",
    "    print(cfg_org)\n",
    "    \n",
    "OmegaConf.resolve(cfg_org)\n",
    "\n",
    "print('resume: ', cfg_org.training.resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_checkpoint_dir = \"/home/carl_lab/diffusion_policy/data/outputs/2024.12.13/03.05.17_train_diffusion_unet_pick_duck_image/\"\n",
    "last_checkpoint_dir = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDiffusionUnetHybridWorkspace(BaseWorkspace):\n",
    "    include_keys = ['global_step', 'epoch']\n",
    "\n",
    "    def __init__(self, cfg: OmegaConf, output_dir=None):\n",
    "        super().__init__(cfg, output_dir=output_dir)\n",
    "\n",
    "        # set seed\n",
    "        seed = cfg.training.seed\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        # configure model\n",
    "        self.model: DiffusionUnetHybridImagePolicy = hydra.utils.instantiate(cfg.policy)\n",
    "\n",
    "        self.ema_model: DiffusionUnetHybridImagePolicy = None\n",
    "        if cfg.training.use_ema:\n",
    "            self.ema_model = copy.deepcopy(self.model)\n",
    "\n",
    "        # configure training state\n",
    "        self.optimizer = hydra.utils.instantiate(\n",
    "            cfg.optimizer, params=self.model.parameters())\n",
    "\n",
    "        # configure training state\n",
    "        self.global_step = 0\n",
    "        self.epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recreating workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['ee_states', 'gripper_states', 'joint_states']\n",
      "using obs modality: rgb with keys: ['eye_in_hand_rgb']\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: scan with keys: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carl_ma/miniconda3/envs/robodiff/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/carl_ma/miniconda3/envs/robodiff/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion params: 2.528022e+08\n",
      "Vision params: 1.119709e+07\n",
      "output dir:  /home/carl_ma/Riad/diffusion_policy/data/outputs/custom2025_02_20_14_10_11\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "output_dir = f\"/home/carl_ma/Riad/diffusion_policy/data/outputs/custom{timestamp}\"\n",
    "os.mkdir(output_dir)\n",
    "workspace = TrainDiffusionUnetHybridWorkspace(cfg_org, output_dir=output_dir)\n",
    "self = workspace\n",
    "print('output dir: ', output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = copy.deepcopy(self.cfg)\n",
    "\n",
    "# resume training\n",
    "# if cfg.training.resume:\n",
    "#     lastest_ckpt_path = self.get_checkpoint_path()\n",
    "#     if lastest_ckpt_path.is_file():\n",
    "#         print(f\"Resuming from checkpoint {lastest_ckpt_path}\")\n",
    "#         self.load_checkpoint(path=lastest_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring lock on cache.\n",
      "Loading cached ReplayBuffer from Disk.\n",
      "Loaded!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1424"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_config = OmegaConf.to_container(cfg.task.dataset, resolve=True )\n",
    "del new_config['_target_']\n",
    "\n",
    "if \"shape_meta\" not in new_config:\n",
    "    raise ValueError(\"shape_meta is missing in dataset configuration\")\n",
    "\n",
    "dataset = RobomimicReplayImageDataset(**new_config)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_dataloader = {key:value for key,value in cfg.dataloader.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replay Buffer Keys: KeysView(<zarr.hierarchy.Group '/data'>)\n",
      "Action Shape: (1743, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Replay Buffer Keys:\", dataset.replay_buffer.keys())\n",
    "print(\"Action Shape:\", dataset.replay_buffer['action'].shape if 'action' in dataset.replay_buffer else \"Missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowdim Keys: ['ee_states', 'joint_states', 'gripper_states']\n",
      "Key ee_states shape: (1743, 16)\n",
      "Key joint_states shape: (1743, 7)\n",
      "Key gripper_states shape: (1743, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Lowdim Keys:\", dataset.lowdim_keys)\n",
    "for key in dataset.lowdim_keys:\n",
    "    if key not in dataset.replay_buffer:\n",
    "        print(f\"Missing key in replay buffer: {key}\")\n",
    "    else:\n",
    "        print(f\"Key {key} shape: {dataset.replay_buffer[key].shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ee_states\n",
      "Warning: Unhandled key ee_states. Using identity normalizer.\n",
      "joint_states\n",
      "Warning: Unhandled key joint_states. Using identity normalizer.\n",
      "gripper_states\n",
      "Warning: Unhandled key gripper_states. Using identity normalizer.\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(dataset, **cfg_dataloader)\n",
    "normalizer = dataset.get_normalizer()\n",
    "\n",
    "# configure validation dataset\n",
    "val_dataset = dataset.get_validation_dataset()\n",
    "val_dataloader = DataLoader(val_dataset, **cfg.val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['obs', 'action'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch =  next(iter(train_dataloader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16, 10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['action'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2, 3, 240, 320])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['obs']['eye_in_hand_rgb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.model.set_normalizer(normalizer)\n",
    "if cfg.training.use_ema:\n",
    "    self.ema_model.set_normalizer(normalizer)\n",
    "\n",
    "# configure lr scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    cfg.training.lr_scheduler,\n",
    "    optimizer=self.optimizer,\n",
    "    num_warmup_steps=cfg.training.lr_warmup_steps,\n",
    "    num_training_steps=(\n",
    "        len(train_dataloader) * cfg.training.num_epochs) \\\n",
    "            // cfg.training.gradient_accumulate_every,\n",
    "    # pytorch assumes stepping LRScheduler every epoch\n",
    "    # however huggingface diffusers steps it every batch\n",
    "    last_epoch=self.global_step-1\n",
    ")\n",
    "\n",
    "# configure ema\n",
    "ema: EMAModel = None\n",
    "if cfg.training.use_ema:\n",
    "    ema = hydra.utils.instantiate(\n",
    "        cfg.ema,\n",
    "        model=self.ema_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: [0.95, 0.999]\n",
       "    capturable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    initial_lr: 0.0001\n",
       "    lr: 0.0\n",
       "    maximize: False\n",
       "    weight_decay: 1e-06\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_manager = TopKCheckpointManager(\n",
    "    save_dir=os.path.join(self.output_dir, 'checkpoints'),\n",
    "    **cfg.checkpoint.topk\n",
    ")\n",
    "\n",
    "# device transfer\n",
    "device = torch.device(cfg.training.device)\n",
    "self.model.to(device)\n",
    "if self.ema_model is not None:\n",
    "    self.ema_model.to(device)\n",
    "optimizer_to(self.optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output dir:  /home/carl_ma/Riad/diffusion_policy/data/outputs/custom2025_02_20_14_10_11\n"
     ]
    }
   ],
   "source": [
    "print('output dir: ', output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/carl_ma/Riad/diffusion_policy/data/outputs/custom2025_02_20_14_10_11/checkpoints/epoch_0_20250220_141158.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/carl_ma/Riad/diffusion_policy/data/outputs/custom2025_02_20_14_10_11/checkpoints/epoch_100_20250220_143756.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/carl_ma/Riad/diffusion_policy/data/outputs/custom2025_02_20_14_10_11/checkpoints/epoch_200_20250220_150412.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/carl_ma/Riad/diffusion_policy/data/outputs/custom2025_02_20_14_10_11/checkpoints/epoch_300_20250220_153059.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/carl_ma/Riad/diffusion_policy/data/outputs/custom2025_02_20_14_10_11/checkpoints/epoch_400_20250220_155759.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/carl_ma/Riad/diffusion_policy/data/outputs/custom2025_02_20_14_10_11/checkpoints/epoch_500_20250220_162513.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/carl_ma/Riad/diffusion_policy/data/outputs/custom2025_02_20_14_10_11/checkpoints/epoch_600_20250220_165226.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 601:   0%|          | 0/23 [00:00<?, ?it/s]Exception in thread Thread-1214:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/carl_ma/miniconda3/envs/robodiff/lib/python3.9/site-packages/torch/serialization.py\", line 379, in save\n",
      "    _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n",
      "  File \"/home/carl_ma/miniconda3/envs/robodiff/lib/python3.9/site-packages/torch/serialization.py\", line 604, in _save\n",
      "    zip_file.write_record(name, storage.data_ptr(), num_bytes)\n",
      "OSError: [Errno 28] No space left on device\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/carl_ma/miniconda3/envs/robodiff/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/carl_ma/miniconda3/envs/robodiff/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/carl_ma/Riad/diffusion_policy/diffusion_policy/workspace/base_workspace.py\", line 67, in <lambda>\n",
      "    target=lambda : torch.save(payload, path.open('wb'), pickle_module=dill))\n",
      "  File \"/home/carl_ma/miniconda3/envs/robodiff/lib/python3.9/site-packages/torch/serialization.py\", line 380, in save\n",
      "    return\n",
      "  File \"/home/carl_ma/miniconda3/envs/robodiff/lib/python3.9/site-packages/torch/serialization.py\", line 259, in __exit__\n",
      "    self.file_like.write_end_of_file()\n",
      "RuntimeError: [enforce fail at inline_container.cc:319] . unexpected pos 312607936 vs 312607824\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_sampling_batch = None\n",
    "log_path = os.path.join(self.output_dir, 'logs.json.txt')\n",
    "with JsonLogger(log_path) as json_logger:\n",
    "    for local_epoch_idx in range(cfg.training.num_epochs):\n",
    "        step_log = dict()\n",
    "        # ========= train for this epoch ==========\n",
    "        train_losses = list()\n",
    "        with tqdm.tqdm(train_dataloader, desc=f\"Training epoch {self.epoch}\", \n",
    "                leave=False, mininterval=cfg.training.tqdm_interval_sec) as tepoch:\n",
    "            for batch_idx, batch in enumerate(tepoch):\n",
    "                # device transfer\n",
    "                batch = dict_apply(batch, lambda x: x.to(device, non_blocking=True))\n",
    "                if train_sampling_batch is None:\n",
    "                    train_sampling_batch = batch\n",
    "\n",
    "                # compute loss\n",
    "                raw_loss = self.model.compute_loss(batch)\n",
    "                loss = raw_loss / cfg.training.gradient_accumulate_every\n",
    "                loss.backward()\n",
    "\n",
    "                # step optimizer\n",
    "                if self.global_step % cfg.training.gradient_accumulate_every == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "                    lr_scheduler.step()\n",
    "                \n",
    "                # update ema\n",
    "                if cfg.training.use_ema:\n",
    "                    ema.step(self.model)\n",
    "\n",
    "                # logging\n",
    "                raw_loss_cpu = raw_loss.item()\n",
    "                tepoch.set_postfix(loss=raw_loss_cpu, refresh=False)\n",
    "                train_losses.append(raw_loss_cpu)\n",
    "                step_log = {\n",
    "                    'train_loss': raw_loss_cpu,\n",
    "                    'global_step': self.global_step,\n",
    "                    'epoch': self.epoch,\n",
    "                    'lr': lr_scheduler.get_last_lr()[0]\n",
    "                }\n",
    "\n",
    "                is_last_batch = (batch_idx == (len(train_dataloader)-1))\n",
    "                if not is_last_batch:\n",
    "                    # log of last step is combined with validation and rollout\n",
    "                     \n",
    "                    json_logger.log(step_log)\n",
    "                    self.global_step += 1\n",
    "\n",
    "                if (cfg.training.max_train_steps is not None) \\\n",
    "                    and batch_idx >= (cfg.training.max_train_steps-1):\n",
    "                    break\n",
    "\n",
    "        # at the end of each epoch\n",
    "        # replace train_loss with epoch average\n",
    "        train_loss = np.mean(train_losses)\n",
    "        step_log['train_loss'] = train_loss\n",
    "\n",
    "        # ========= eval for this epoch ==========\n",
    "        policy = self.model\n",
    "        if cfg.training.use_ema:\n",
    "            policy = self.ema_model\n",
    "        policy.eval()\n",
    "\n",
    " \n",
    "        # run validation\n",
    "        if (self.epoch % cfg.training.val_every) == 0:\n",
    "            with torch.no_grad():\n",
    "                val_losses = list()\n",
    "                with tqdm.tqdm(val_dataloader, desc=f\"Validation epoch {self.epoch}\", \n",
    "                        leave=False, mininterval=cfg.training.tqdm_interval_sec) as tepoch:\n",
    "                    for batch_idx, batch in enumerate(tepoch):\n",
    "                        batch = dict_apply(batch, lambda x: x.to(device, non_blocking=True))\n",
    "                        loss = self.model.compute_loss(batch)\n",
    "                        val_losses.append(loss)\n",
    "                        if (cfg.training.max_val_steps is not None) \\\n",
    "                            and batch_idx >= (cfg.training.max_val_steps-1):\n",
    "                            break\n",
    "                if len(val_losses) > 0:\n",
    "                    val_loss = torch.mean(torch.tensor(val_losses)).item()\n",
    "                    # log epoch average validation loss\n",
    "                    step_log['val_loss'] = val_loss\n",
    "\n",
    "        # run diffusion sampling on a training batch\n",
    "        if (self.epoch % cfg.training.sample_every) == 0:\n",
    "            with torch.no_grad():\n",
    "                # sample trajectory from training set, and evaluate difference\n",
    "                batch = dict_apply(train_sampling_batch, lambda x: x.to(device, non_blocking=True))\n",
    "                obs_dict = batch['obs']\n",
    "                gt_action = batch['action']\n",
    "                \n",
    "                result = policy.predict_action(obs_dict)\n",
    "                pred_action = result['action_pred']\n",
    "                mse = torch.nn.functional.mse_loss(pred_action, gt_action)\n",
    "                step_log['train_action_mse_error'] = mse.item()\n",
    "                del batch\n",
    "                del obs_dict\n",
    "                del gt_action\n",
    "                del result\n",
    "                del pred_action\n",
    "                del mse\n",
    "        \n",
    "        # checkpoint\n",
    "        if (self.epoch % 100) == 0:\n",
    "            timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            # self.save_checkpoint(tag=f'epoch_{self.epoch}') \n",
    "            checkpoint_name = f'epoch_{self.epoch}_{timestamp}'\n",
    "            path_ = self.save_checkpoint(tag=checkpoint_name)\n",
    "            print(path_)\n",
    "\n",
    "            \n",
    "        # ========= eval end for this epoch ==========\n",
    "        policy.train()\n",
    "\n",
    "        # end of epoch\n",
    "        # log of last step is combined with validation and rollout\n",
    "         \n",
    "        json_logger.log(step_log)\n",
    "        self.global_step += 1\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 879/60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# took 1184m  = 19.13333 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/carl_lab/diffusion_policy/data/outputs/custom2025_01_24_20_33_34/checkpoints/after_train_1000_epochs.ckpt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.save_checkpoint(tag=f\"after_train_{self.epoch}_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
